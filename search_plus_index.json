{"./":{"url":"./","title":"ASP.NET Core + React/Flutter","keywords":"","body":"ASP.NET Core + React 全栈开发项目 本项目基于 ASP.NET Core 后端和 React 前端进行开发, 实现的功能是一个简易的社交网络网站. 主要是学习视频的一个配套记录和实现. "},"c1/r.html":{"url":"c1/r.html","title":"第 1 章: \"Walking Skeleton\" 服务端","keywords":"","body":"第一章: 服务端 \"Walking Skeleton\" 第一章主要介绍如何使用 ASP.NET Core 来开发后端, 实现主体框架. 在 .NET Core 中, assembly 间的引用是可传递的, 即在 assemblyA 中引用了 assemblyB, assemblyC 又去引用 assemblyA 的话, 则直接就可以在 assemblyC 中使用到 assemblyB. "},"c1/1.html":{"url":"c1/1.html","title":"1 服务端","keywords":"","body":"Code First 的总体步骤 1 创建初始迁移 定义模型 Entity, 一般而言, 都是在 Domain 中定义. 需要用到 Microsoft.EntityFrameworkCore 包中的 DbContext, 引入即可. 定义 DbContext 子类, 一般而言, 都是在 Infrastructure 中定义. 设置连接字符串, 连接字符串的写法如下所示, 不同数据库写法不一: \"ConnectionStrings\": { \"Default\": \"Server=localhost,14331;User Id=sa;Password=Showgp!@#;\" } 关于连接字符串的写法, 详见这个网站. 注: 上述这个连接字符串中信息不完整, 无法工作, 解决方案请看 1.3 节. 在 Startup 中注入 DbContext, 由于使用 UseSqlServer, 故引入 Microsoft.EntityFrameworkCore.SqlServer 包, 然后写注入代码: services.AddDbContext(builder => { var connectionString = Configuration.GetConnectionString(\"Default\"); builder.UseSqlServer(connectionString: connectionString); }); 数据迁移需要用到 Microsoft.EntityFrameworkCore.Design 包, 引入并创建初始化迁移: dotnet ef migrations add InitialCreate -p src/Reactivities.Infrastructure -s src/Reactivities.Web 其中 -p 参数指定 DbContext 所在的 lib, -s 用于指定 startup 工程. 初始迁移创建后, 只是生成了用于迁移的若干命令, 需要执行迁移才能把改动同步到数据库. 初始迁移创建完毕后, 仅仅生成了数据迁移相关的代码, 并没有实际进行迁移. 要进行迁移有两种办法, 一种是在命令行通过 dotnet ef 相关命令, 一种是在代码中. 我们这次使用代码中执行迁移的方式, 即: 检查是否已执行了最新的迁移, 如果没有, 则执行. 这样可以保证每次程序启动都可以让数据库 schema 和代码同步. 2 代码中检查和执行迁移 迁移检查/执行的代码一般都添加到 Main 函数中. 先改造默认生成的 Main 内容, 改为如下: public static void Main(string[] args) { var host = CreateHostBuilder(args).Build(); // 经过了 build 调用, 此时已经把整个 Startup 的服务等都注入好了. // 此时只需要通过如下方式获取即可. using (var scope = host.Services.CreateScope()) { var services = scope.ServiceProvider; var logger = services.GetRequiredService>(); try { var context = services.GetRequiredService(); // 获取到 context 之后, 进行迁移的检查和运行. context.Database.Migrate(); logger.LogInformation(\"已执行迁移!\"); } catch (Exception ex) { logger.LogError(ex, \"在迁移时发生错误!\"); } } host.Run(); } 上述代码中由于要使用 DbContext 服务对象, 故通过特殊的注入方式获取它. 3 迁移代码执行后不符预期的处理 当执行了上述代码后, log 中给出\"已执行迁移\"的信息, 但数据库中没有生成对应内容. 需要看看这个是什么原因. 检查发现 SQL Server 的连接字符串必须要按照规范填写, 否则无法实现相应功能. 比如之前的连接字符串中没有 Database 字段, 故无法进行迁移. 所以将连接字符串修改为如下: \"ConnectionStrings\": { \"Default\": \"Server=localhost,14331;Database=Reactivities;User Id=sa;Password=Showgp!@#;\" } 为了演示方便, 没有将用户名和密码使用安全存储保存, 但在生产环境下千万要使用安全存储, 而不能直接把用户名密码等敏感信息使用明文写到配置中. 4 指定测试数据 测试数据可以通过重写 OnModelCreating 方法, 在其中使用 HasData: /// /// 通过重写这个方法来进一步配置 Entity. /// /// protected override void OnModelCreating(ModelBuilder modelBuilder) { modelBuilder.Entity().HasData( new Value { Id = 1, Name = \"Helloworld\"}, new Value { Id = 2, Name = \"Helloworld\"}, new Value { Id = 3, Name = \"Helloworld\"}, new Value { Id = 4, Name = \"Helloworld\"} ); } 有了这些代码后, 添加一个新的迁移: dotnet ef migrations add SeedValues -p src/Reactivities.Infrastructure -s src/Reactivities.Web 再次运行工程即可将这个迁移的内容同步到数据库了. (如果没有写迁移执行代码, 则还可以使用命令行来手动执行迁移) "},"c1/2.html":{"url":"c1/2.html","title":"2 API 骨架","keywords":"","body":"通过 API 向外界提供数据服务 需要实现控制器和动作方法来向外部提供 API 服务. 新建一个控制器, 如下所示: using System.Collections.Generic; using System.Threading.Tasks; using Microsoft.AspNetCore.Mvc; using Microsoft.EntityFrameworkCore; using Reactivities.Domain; using Reactivities.Infrastructure; namespace Reactivities.Web.Controllers { [ApiController] [Route(\"api/[controller]\")] public class ValueController : ControllerBase { private readonly DataContext _context; public ValueController(DataContext context) { _context = context; } [HttpGet] public async Task>> GetAll() { var items = await _context.Values.ToListAsync(); return Ok(items); } } } 在其中注入 context 用于数据获取, 但更好的方式是使用诸如 Repository 等模式来封装 DBContext, 从而在控制器中使用 Repository 接口而非 DBContext 实现类. "},"c1/3.html":{"url":"c1/3.html","title":"3 附 docker 数据库配置","keywords":"","body":"附 docker 数据库配置 docker 关于 Docker 的代理设置, 详见这篇文章. 软件包括: MySQL server 和 MySQL workbench. 为了使用数据库服务器, 这里采用了 docker 的方式安装, 参考官方文档来进行整个过程. 另外官方有一个文档, 更多配置也非常值得参考, 主要是针对 docker 中 MySQL 的配置. 其中一个命令非常好, 就是打开某个容器的 bash 命令行: docker exec -it 容器名称 bash 尝试连接数据库: 运行: docker run --name mysql1 -p 33060:3306 -e MYSQL_ROOT_PASSWORD=124tiger -d mysql/mysql-server:5.7 Docker 的外部连接问题着实比较困扰, 暂时先安装普通版本的练习后再使用 Docker 版的. MySQL 的安装, 需要参考如下两个链接: https://www.mysqltutorial.org/install-mysql-centos/ https://www.linode.com/docs/databases/mysql/how-to-install-mysql-on-centos-7/ 第一个链接中说明如何安装 8.0, 第二个链接中的可以参考它如何启动 sudo systemctl start mysqld 的, 否则之后的步骤无法进行下去. 两个数据表之间的关系就是 Relationship. 这样的话就可以把关联的数据分割到不同的表中, 从而简化表的设计. 首先来看外键的定义(ForeignKey): 用于唯一标识另外一张表中的一条记录. 如果在一张表中有一条记录的某个键值表示外键, 则这个外键就引出了它关联的另外一个记录, 这个记录在另外一张表中. 多对多的关系在建表的时候, 多数 DBMS 都不支持直接建立多对多的表结构. 此时就需要使用 join 来处理. docker run -itd --name mysql1 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql 最后发现运行出错是因为拉错了 Image... 使用官方 Image 拉取官方 Image 后, 准备好 MySQL 的工作目录, 参考这个链接. 参考这篇文章可以很容易理解一些基础概念. 建立目录结构, 分别是 logs, data, conf. 在启动容器的时候指定挂载文件夹: docker run -p 20202:3306 --name=mysql1 -v $PWD/logs:/logs -v $PWD/data:/mysql_data -e MYSQL_ROOT_PASSWORD=123456 -d mysql 如果使用数据卷, 则: docker run -p 20202:3306 --name=mysql1 -v mysql1Logs:/logs -v mysql1logData:/mysql_data -e MYSQL_ROOT_PASSWORD=123456 -d mysql 如果想要挂载自定义配置文件, 则再加一个 -v $PWD/conf/my.cnf:/etc/mysql/my.cnf 即可. 而后使用任意客户端就可以进行连接了. MSSQL + EF Core 参考官方文档. 使用 MSSQL 的 docker 镜像: docker pull mcr.microsoft.com/mssql/rhel/server 然后启动: docker run -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=' -p 1401:1433 -d mcr.microsoft.com/mssql/server 可以正常连接. 使用外部数据卷进行数据持久化: docker run -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=' -p 1433:1433 -v /data:/var/opt/mssql/data -v /log:/var/opt/mssql/log -v /secrets:/var/opt/mssql/secrets -d mcr.microsoft.com/mssql/server --name=mssql1 不过这个方法在 macOS 上暂时不支持, 故官方文档中使用 data volume containers. data volume containers: docker run --name=mssql1 -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=' -p 14331:1433 -v sql1volume:/var/opt/mssql -d mcr.microsoft.com/mssql/server 通过简单的命令就可以使用数据卷容器, 且即便是容器销毁了, 数据也不会丢失. 可以使用如下命令来列出数据卷列表: docker volume ls 连接到数据库后, 即可进行各种数据库操作了. SELECT @@VERSION 使用 docker cp 命令将主机上的文件拷贝到数据卷上: // 从 host 拷贝到容器 docker cp /path/to/file ContainerName:/path/inside/container // 从容器拷贝到 host docker cp ContainerName:/path/inside/container/file /path/to/host /var/opt/mssql/data 这样就可以进行双向拷贝操作了. 因为在 macos 上找不到容器的文件目录... MySQL 和 EF Core 首先获取 mysql image, 然后开始后续操作, 主要步骤为: 启动 mysql 容器. 将 DbContext 配置修改为 mysql 进行数据迁移. 验证执行效果. 启动容器 容器可以设置为默认端口 3306, 且可以将重启策略设置为一直重启. 然后将数据卷进行映射. docker container run --restart always -d --name=mysql1 \\ -p 3306:3306 \\ -v 数据卷名称或host文件夹路径:/var/lib/mysql \\ -e 'MYSQL_ROOT_PASSWORD=xxxxxxxx' \\ mysql "},"c2/r.html":{"url":"c2/r.html","title":"第 2 章: \"Walking Skeleton\" 客户端","keywords":"","body":"第二章: 客户端 \"Walking Skeleton\" 第二章开始使用 React 搭建客户端 APP. "},"c2/1.html":{"url":"c2/1.html","title":"1 概述","keywords":"","body":"React 客户端开发概述 首先使用如下命令创建客户端工程: npx create-react-app client-app --use-npm --typescript 创建完成后, 通过如下命令即可运行创建的工程: npm start React 的相关概念 传统的 Web 应用和 React 应用有区别, 在 React 中, 把 HTML/CSS/JS 都组合到一个 Component 中, 即一个视图或视图部分. 每个 Component 都拥有自己的 State, 它们还可以接收 Prop, 即从父组件向子组件传递的数据. 当组件内的 prop 改变时, 就会触发虚拟 DOM 的重建, 并更新真实的 DOM, 这个和 Flutter 比较类似. 另外 React 是拥有单向数据绑定, 即绑定是从 Component 到虚拟 DOM 的, 当 Component 的数据改变时自动把数据同步到虚拟 DOM. 所有的 Component 都是 JSX 语法实现的. Typescript 简介 特点: 强类型 面向对象 生产力强 兼容性 丰富的三方支持 一个简单的例子如下所示: const car = 1 interface ICar { color: string model: string } const car1 = { color: 'red', model: 'Mes', type: 1, } const car2: ICar = { color: 'blue', model: 'BMW' } const multiply = (x: number, y: number): number => { return x * y } "},"c2/2.html":{"url":"c2/2.html","title":"2 通过客户端访问 API 数据","keywords":"","body":"通过 Flutter 实现客户端读取 API 数据 目前主要任务是介绍 ASP.NET Core, 故没有必要先入手 React. 先用 Flutter 客户端代替. 新建 API 客户端: flutter create reactivities_client, 这个命令会隐式地使用 swift/kotlin 作为原生端开发语言. 在客户端中, 通过 dio 构造一个数据访问客户端, 即可对后端进行访问. 只要完成骨架即可开始后续内容. "},"c3/r.html":{"url":"c3/r.html","title":"第 3 章: 后端 Acvitity 接口实现","keywords":"","body":"第三章 后端 APP 的更多内容 本章需要实现 Activity 的 CRUD, 此外还有如下内容: Thin API Controller MediatR CQRS + MediatR "},"c3/1.html":{"url":"c3/1.html","title":"1 添加 Activity 表和 Seed Data","keywords":"","body":"添加 Activity 表和 Seed Data 需要实现 Activity 的增删改查. 首先新建对应的 Application Model, 名为 Activity: public class Activity { public Guid Id { get; set; } public String Title { get; set; } public String Description { get; set; } public String Category { get; set; } public DateTime Date { get; set; } public String City { get; set; } public String Venue { get; set; } } 在 DbContext 中新增一个 DbSet: public DbSet Activities { get; set; } 创建一个新的迁移: dotnet ef migrations add \"ActivityEntityAdded\" -p src/Reactivities.Infrastructure -s src/Reactivities.Web 迁移创建后, 由于之前已经在启动 APP 的时候设置了自动执行迁移的代码, 故只需要运行 APP 即可看到在 SQL Server 中新建了一张 Activity 表. 下一步是向这张表中添加一些测试数据, 之前第一次的做法是在 DbContext 的子类的 OnModelCreating 方法内写数据并创建迁移, 但这个办法有不好的地方, 就是我们必须手动创建每一个 Entity 的 Id, 但如果是一张有关联表的表数据, 这样的做法就很考脑壳了. 故使用新的方法: 首先新建一个 Seed 类, 在其中新建一个静态方法 SeedData, 然后将 DbContext 子类作为参数传入: public class Seed { public static void SeedData(DataContext context) { // TODO: 需要在 Debug 时候才 Seed, Release 的时候不需要. if (!context.Activities.Any()) { var activities = new List { new Activity { Title = \"Past Activity 1\", Date = DateTime.Now.AddMonths(-2), Description = \"Activity 2 months ago\", Category = \"drinks\", City = \"London\", Venue = \"Pub\", }, // ... } // 持久化 context.Activities.AddRange(activities); context.SaveChanges(); } } } 测试数据在教程有中提供, 可以直接把 code-snippet 拖到 .vscode 文件夹下, 就可以通过快捷键方式输入了. 在 APP 启动的时候, Main 函数中获取 context 服务的时候调用这个方法: public static void Main(string[] args) { var host = CreateHostBuilder(args).Build(); using (var scope = host.Services.CreateScope()) { var services = scope.ServiceProvider; var logger = services.GetRequiredService>(); try { var context = services.GetRequiredService(); context.Database.Migrate(); Seed.SeedData(context); logger.LogInformation(\"已执行迁移!\"); } catch (Exception ex) { logger.LogError(ex, \"在迁移时发生错误!\"); } } host.Run(); } 运行 APP 后, Seed 的数据就都写入到数据库中了. "},"c3/2.html":{"url":"c3/2.html","title":"2 CQRS: 命令查询职责分离","keywords":"","body":"CQRS: 命令查询职责分离 我们将要做的是把 Command 和 Query 分离开来, 因为二者的不同点就在于是否会修改状态, 以及是否有返回数据. 这样的做法就是 CQRS, 即命令查询职责分离的缩写. 形式1: 读写同一个数据源 CQRS 的关注点是 APP 中的数据流转过程, 如下图所示: Command 的数据是从上往下流向数据源的, 而 Query 的数据是从下往上流向 API 的. 形式2: 读写不同数据源 更复杂的例子就是分离查询和写入的数据库, 这样的实现可以很大程度保证性能, 如下图所示: 使用这种数据库分离结构的前提是当前的 APP 读取数据的频率远远高于写入数据的频率. 比如现代的社交网络 APP, 当发了一条动态后, 隔几秒钟才显示出来的情况用户也是可以接受的. 形式3: 使用 Event Store 还有一类做法是把命令数据流向一个 Event Store, 然后再同步到数据源中, 如下所示: 这个做法下, 将命令暂存到 Event Store 而非写入数据库, 这样的话, 通过 Event Store 中的 Event 就可以把当前 APP 状态的修改同步到数据源中. 这样的方式就类似通过 Event Store 来记账, 最后通过每个 Event 来修改数据的最终状态. "},"c3/3.html":{"url":"c3/3.html","title":"3 清晰架构实现1: MediatR","keywords":"","body":"清晰架构实现1: MediatR 当前架构如下所示: 下一个步骤是在 Application 层中实现一些 Handler 用于获取数据. 通过 MediatR 来让 API Controller 向 Handler 发送数据. 要实现这样的结构, 先看看 MediatR 是什么. MediatR 简介 MediatR 是.NET中的简单中介者模式实现，一种进程内消息传递机制（无其他外部依赖）。 支持以同步或异步的形式进行请求/响应，命令，查询，通知和事件的消息传递，并通过C#泛型支持消息的智能调度。 中介者(Mediator)模式如下图所示: . 通过中介者模式, 可以将以前杂乱无章的对象间通信进行整合: 更多有关 MediatR 的内容, 详见这个系列教程. 使用 MediatR 库实现对象间通信 过程如下所示: 在 Application 层工程中引入 MediatR 库 MediatR.Extensions.Microsoft.DependencyInjection. 新建一个 List.cs 文件, 用于向上提供获取 Activity List 的服务. 实现 Request 和 Handler 配套方法: public class ActivityList { public class Query : IRequest> {} public class Handler : IRequestHandler> { private readonly DataContext _context; public Handler(DataContext context) { _context = context; } public async Task> Handle(Query request, CancellationToken cancellationToken) { var list = await _context.Activities.ToListAsync(); return list; } } } 通过上述代码就封装了一个获取 Activity List 的功能类了. 外部向 MediatR 发送对应请求, MediatR 将请求转发给这个类, 然后获取结果. 创建发送请求的 API 控制器 有了 MediatR, 把请求发送者和处理者之间进行解耦, 强类型方式的处理, 在使用者端就非常简单了, 同时把业务也完全封装到了 Application 层中. API 控制器如下所示: public class ActivitiesController : BaseAPIController { private readonly IMediator _mediator; public ActivitiesController(IMediator mediator) { // 注入 MediatR 对象 _mediator = mediator; } [HttpGet] public async Task>> List() { // 使用者只需要发送对应的请求并等待结果即可. 由 mediator 对请求进行转发. return await _mediator.Send(new ActivityList.Query()); } } 然后将 MediatR 注入到依赖管理容器: // 注入 MediatR 服务. services.AddMediatR(typeof(ActivityList).Assembly); 其中参数是所有 Handler 存放的 Assembly, 一般都把这些 Handler 类存放到业务逻辑层中, 组织方式上也很灵活, 像上面那样就是包裹在一个类里面, 避免开发者抓破脑袋想名字... 传入 ActivityList 类只是为了方便定位 Application 层工程对应的 Assembly, 实际上传入其中随便一个类都可以. "},"c3/4.html":{"url":"c3/4.html","title":"4 实现其他几个 Activity 操作: CRUD","keywords":"","body":"实现其他几个 Activity 操作: CRUD 查询 Activity Detail API 这个类负责提供对应的 Query 和 Handler, 如下所示: public class ActivityDetails { public class Query : IRequest { public Guid Id { get; set; } } public class Handler : IRequestHandler { private readonly DataContext _context; public Handler(DataContext context) { this._context = context; } public async Task Handle(Query request, CancellationToken cancellationToken) { var activity = await _context.Activities.FindAsync(request.Id); return activity; } } } 同样在 ActivitiesController 中提供对应的 API: [HttpGet(\"{id}\")] public async Task> Details(Guid id) { var result = await _mediator.Send(new ActivityDetails.Query { Id = id }); if (result == null) return NotFound(); return result; } 这样外界通过形如 {{baseurl}}/api/activities/{id} 就可以进行接口请求. 如果传入的是一个不存在的 Id, 则返回的是 400 错误, 而非希望的 404, 所以需要进行错误处理. 错误处理的内容放到后续内容, 这里不讲. 下一步先来看看使用 CancellationToken. CancellationToken 的使用 如果一个耗时处理过程正在进行, 但如果用户或外部出现某个事件让之前的处理过程已经没有必要, 则需要对之前的处理过程进行取消, 此时就可以使用之前的处理过程对应的 CancellationToken 来取消这个处理过程. 为了演示方便, 在之前我们实现的 Detail Action 方法上进行延时操作, 这样可以模拟之后用户的刷新或取消请求过程: public async Task> Handle(Query request, CancellationToken cancellationToken) { try { for (var i = 0; i 其中的 for 用于模拟耗时操作, 如果外部没有取消, 则会每次打印 Task {i} has completed, 而如果外部取消了, 则会打印 Task was cancelled 并抛出异常. 下一步就是在 API Controller 中进行处理, 接收外部的请求取消操作: [HttpGet] public async Task>> List(CancellationToken token) { return await _mediator.Send(new ActivityList.Query(), token); } 下面就可以在 Postman 中进行请求了, 点击取消请求即可看到效果. 创建 Activity API 根据 CQRS 原则, 创建的 API 使用的是 Command. 首先建立一个类来实现 Command 和 Handler: public class ActivityCreate { public class Command : IRequest { public Guid Id { get; set; } public String Title { get; set; } public String Description { get; set; } public String Category { get; set; } public DateTime Date { get; set; } public String City { get; set; } public String Venue { get; set; } } public class Handler : IRequestHandler { private readonly DataContext _context; public Handler(DataContext context) { _context = context; } // Unit 类型在 MediatR 中表示的仅是空数据类型. public async Task Handle(Command request, CancellationToken cancellationToken) { var activity = new Activity { Id = request.Id, Title = request.Title, Description = request.Description, Category = request.Category, Date = request.Date, City = request.City, Venue = request.Venue, }; _context.Activities.Add(activity); var success = await _context.SaveChangesAsync() > 0; if (success) return Unit.Value; throw new Exception(\"Problem saving changes\"); } } } 而后提供 API 接口: [HttpPost] public async Task Create(ActivityCreate.Command command) { await _mediator.Send(command); return Ok(); } Postman 的一个小技巧 再使用 Postman 来测试一下接口, 这里使用到了 Postman 中的一些预定义环境变量, 并使用 Pre-request Script 来生成日期: { \"id\": \"{{$guid}}\", \"title\": \"{{$randomCatchPhraseNoun}}\", \"description\": \"{{$randomVerb}}, {{$randomVerb}}\", \"category\": \"{{$randomNoun}}\", \"date\": \"{{activityDate}}\", \"city\": \"{{$randomCity}}\", \"venue\": \"{{$randomAdjective}}\" } 其中 {{}} 包裹的就是当前可用的变量, $ 前缀的是预定义环境变量, 在 Postman 的文档中可用查询到. 另外通过 Pre-request Script 定义了一个日期 {{activityDate}}, 脚本如下所示: var moment = require(\"moment\"); var date = moment().add(14, 'days').toISOString(); // 把 activityDate 设置到当前请求的环境变量中 pm.environment.set(\"activityDate\", date); "},"c3/5.html":{"url":"c3/5.html","title":"5 添加 Swagger 支持","keywords":"","body":"5 添加 Swagger 支持 马上要开始客户端的开发, 但是没有一个文档总是感觉缺少点东西, 故先引入 Swagger, 展示 API. 引入 Swagger 包: Swashbuckle.AspNetCore. 添加 Swagger 服务, 如下所示: services.AddSwaggerGen(config => { config.SwaggerDoc(\"v1\", new OpenApiInfo { Title = \"My API\", Version = \"v1\" }); }); 在请求处理管线中添加 Swagger: // 允许中间件生成 Swagger JSON 端点. app.UseSwagger(); // 提供 Swagger UI. app.UseSwaggerUI(c => { c.SwaggerEndpoint(\"/swagger/v1/swagger.json\", \"My API V1\"); }); 启动 APP 后即可通过 http://localhost:5000/swagger/index.html 链接访问了. "},"c4/r.html":{"url":"c4/r.html","title":"第 4 章: Flutter 实现的前端","keywords":"","body":"第 4 章: Flutter 实现的前端 用 Flutter 来实现前端, 便于跟着教程继续练习. "},"c4/1.html":{"url":"c4/1.html","title":"1 基盘搭建概述","keywords":"","body":"基盘搭建概述 需要完成的内容如下所示: 基盘搭建: 使用 DIO 作为数据访问层支持库, 使用 Fluro 作为路由管理框架, 使用 Provider 作为状态管理框架. 页面: activity 列表页 activity 详情页 activity 编辑页 activity 添加页 其中添加页和编辑页可以使用同一个页面. 此外探索 Provider 的全局和局部状态管理实现. "},"c4/2.html":{"url":"c4/2.html","title":"2 使用 DIO 搭建数据访问层","keywords":"","body":"使用 DIO 搭建数据访问层 数据访问层总体上使用一个接口提供若干分接口的模式实现, 类似如下风格: public interface IAPIClient { public IActivityClient activityClient { get; } public IValueClient valueClient { get; } } 这样的风格是模仿 Octokit 的 Github Client 来的, 比较实用. 外界使用时只需要制造一个客户端对象即可, 为了让外界使用更有灵活性, 一般不设置为单例. 下面先来介绍一些 DIO 的使用, 大部分是跟着官方文档来的. 下面是 Dio 的基本配置方式: final options = BaseOptions( baseUrl: apiBaseUrl, sendTimeout: kSendTimeout, receiveTimeout: kReceiveTimeout, ); _client = Dio(options); 可以通过拦截器来对每个请求进行拦截加工: Dio _makeDioClient() { final options = BaseOptions( baseUrl: apiBaseUrl, sendTimeout: kSendTimeout, receiveTimeout: kReceiveTimeout, ); final client = Dio(options); final interceptor = InterceptorsWrapper( onRequest: (RequestOptions options) async { // TODO: addAll 的时候 other 不能被改动, 这里是否会成为一个缺陷点? if (_additionalHeaders != null && _additionalHeaders.isNotEmpty) options.headers.addAll(_additionalHeaders); return options; }, ); client.interceptors.add(interceptor); return client; } "},"c4/3.html":{"url":"c4/3.html","title":"3 使用 Fluro 搭建路由系统","keywords":"","body":"使用 Fluro 搭建路由系统 Fluro 是一个比较实用的路由管理框架, 它提供了一套简化 Flutter 路由管理的功能, 并且提供很灵活的路由注册方式. 只需要两个步骤即可: 注册路由: 通过 router.define 的方式注册路由 builder 和对应的路径. 将路由表提供给 Flutter: 在 AppWidget 的 onGenerateRoute 中提供参数 router.generator. 如果是多人开发, 则可以将各个场景的注册分布到不同的文件中, 然后使用统一的注册接口传入进行注册. 一个简单的例子: "},"c5/r.html":{"url":"c5/r.html","title":"第 5 章 数据验证和错误处理","keywords":"","body":"第 5 章 数据验证和错误处理 本章主要介绍如何进行后端数据验证和错误处理. "},"c5/1.html":{"url":"c5/1.html","title":"1 数据验证","keywords":"","body":"数据验证 通过对客户端请求数据的验证, 可以让服务端根据错误进行对应的响应, 比如返回 400 错误或其他的一些自定义错误内容. 主要包括: 使用注解对数据进行验证 使用 Fluent API 方式对数据进行验证 在本 APP 中主要使用第二种方式来进行数据验证, 即对 Command 的数据进行验证. 需要引入一个 Fluent Validation 包, 然后针对需要验证的数据设置验证规则, 如下图所示: 实现 Fluent 方式的数据验证 目前由于没有进行数据验证, 故后端 APP 在接收到任何请求后都会进行处理, 如果数据异常, 则直接会抛出异常. 比如发送一个空的 Activity 到服务端, 此时后端仍然会接收并处理这个请求, 并且把空的数据插入到数据库, 但这样的行为是不希望发生的. 在使用 MediatR 的时候, 就可以在比如 Command 和 Handler 之间, 添加一层 Validation 过程. 为此, 如要进行如下步骤: 添加 FluentValidation 包: FluentValidation.AspNetCore 添加 Validation 子类: public class CommandValidator : AbstractValidator { public CommandValidator() { RuleFor(x => x.Title).NotEmpty(); // 其他的验证... } } 在服务中注入 Validator 依赖(在现有的 AddControllers 方法后链上一个 AddFluentValidation 调用): services.AddControllers().AddFluentValidation(config => { // 框架会自动在包含指定类型的 Assembly 中寻找 AbstractValidator 子类. config.RegisterValidatorsFromAssemblyContaining(); }); "},"c5/2.html":{"url":"c5/2.html","title":"2 错误处理","keywords":"","body":"错误处理 总体思路如下: 创建 APP 自己特有的错误体系 创建一个用于处理 APP 自己错误体系的中间件 业务层在相关错误发生时, 直接抛出对应的错误 中间件在接收到可以处理的错误时, 将错误转换为对应的状态码响应发送回去. 创建自定义错误类型 错误的定义可以在 Domain 中, 这样方便各个模块使用. 这里仅为演示, 故直接在 Application 层中定义错误类型: public class RestException : Exception { public HttpStatusCode Code { get; } public object Errors { get; } public RestException(HttpStatusCode code, object errors = null) { this.Errors = errors; this.Code = code; } } 创建自定义错误处理中间件 自定义中间件的要求: 包含一个名为 Invoke 或 InvokeAsync 的方法, 且方法第一个参数必须是 HttpContext 类型的, 其他需要的参数可以自己定, 这些参数都是通过依赖注入提供. 使用约定大于配置的方式进行处理. 构造函数的格式也没有任何要求, 如果需要调用下一个中间件, 则可以在构造函数中传入一个 RequestDelegate 类型参数, 表示下一个中间件. 如下所示: public class ErrorHandlingMiddleware { private readonly ILogger _logger; private readonly RequestDelegate _next; public ErrorHandlingMiddleware(RequestDelegate next, ILogger logger) { _next = next; _logger = logger; } public async Task Invoke(HttpContext context) { // 由于是自定义错误处理中间件, 故希望的是先执行了 next 再来捕捉并处理错误 try { await _next(context); } catch (Exception ex) { await HandleExceptionAsync(context, ex, _logger); } } /// 对错误进行分类处理: 根据错误的类型对响应进行修改. private async Task HandleExceptionAsync(HttpContext context, Exception ex, ILogger logger) { object errors = null; switch (ex) { case RestException re: logger.LogError(ex, \"REST ERROR\"); errors = re.Errors; // C# 中 enum 的 case 值获取方式是直接进行转换 context.Response.StatusCode = (int)re.Code; break; case Exception e: logger.LogError(e, \"SERVER ERROR\"); errors = string.IsNullOrWhiteSpace(e.Message) ? \"Error\" : e.Message; context.Response.StatusCode = (int)HttpStatusCode.InternalServerError; break; } context.Response.ContentType = \"application/json\"; if (errors != null) { var option = new JsonSerializerOptions { // 使用驼峰命名来处理 JSON key PropertyNamingPolicy = JsonNamingPolicy.CamelCase, // pretty printed WriteIndented = true }; // 用一个匿名对象包裹 errors, 避免出现当 errors 是一个字符串的时候返回 JSON 顶层是一个字符串而非 JSON 对象的问题. var result = JsonSerializer.Serialize(new { Error = errors }, option); await context.Response.WriteAsync(result); } } } 使用时, 只需在请求处理管线最开始位置添加: app.UseMiddleware(); // if (env.IsDevelopment()) // { // app.UseDeveloperExceptionPage(); // } 在业务代码中抛出自定义的异常: public async Task Handle(Command request, CancellationToken cancellationToken) { var activity = await _context.Activities.FindAsync(request.Id); if (activity == null) throw new RestException(HttpStatusCode.NotFound, \"无法找到对应的 Activity\"); _context.Remove(activity); var success = await _context.SaveChangesAsync() > 0; if (success) return Unit.Value; throw new Exception(\"删除 Activity 失败\"); } 当客户端使用不存在的 Id 进行删除请求时, 响应体中就携带了错误信息: { \"error\": \"无法找到对应的 Activity\" } "},"c6/r.html":{"url":"c6/r.html","title":"第 6 章 Identity","keywords":"","body":"第 6 章 Identity 本章主要介绍什么是 ASP.NET Core 的 Identity, 以及如何使用 JWT token 进行认证. 另外会创建一个单独的 Identity 工程来提供用户的认证服务. "},"c6/1.html":{"url":"c6/1.html","title":"1 概述","keywords":"","body":"概述 ASP.NET Core 是一个典型的 Membership 系统: 支持登录信息 支持外部的登录服务, 比如 Google provider 等. 提供对用户信息的持久化存储能力 在存储用户密码时, 会对明文进行 hash, 并添加特殊 salt, 即便两个用户密码相同, 但存放在持久化存储中的密码字符串也是不一样的. 且存放密码时, 都是通过 10000 次的加密操作, 具体的算法需要看 Identity 的源码或文档. "},"c6/2.html":{"url":"c6/2.html","title":"2 实现 Identity","keywords":"","body":"实现 Identity 使用独立的 Identity 工程来实现用户认证, 这样的好处是: 所有的服务都可以使用这个工程来进行认证, 而非仅 API 服务. 便于维护和升级 Identity 便于其他工程使用不同的 Identity 机制. 故使用单独的服务来提供认证. Identity 基础设施的搭建 在实际项目中, 通常把表示用户的类放到认证服务所在的工程中, 这样可以避免 Identity 相关的依赖扩散到其他工程中, 便于外部使用以及维护扩展. 但这里为了演示上的方便, 在 Domain 中新建一个 AppUser 类, 这个类表示登录到 APP 的用户. 首先引入 Identity 包: Microsoft.AspNetCore.Identity.EntityFrameworkCore 在 Domain 中新建一个 AppUser 类:public class AppUser : IdentityUser { /// /// 用户的展示名称, 非登录名称. /// /// public String DisplayName { get; set; } } 将 Identity 工程中的 DataContext 类父类修改为 IdentityDbContext, 以支持 Identity 对象的存储能力, 并且在 OnModelCreating 方法第一行添加父类方法调用:// 调用父类, 保证 AppUser 数据在存储的时候可以自动获得一个 primary key 值. base.OnModelCreating(modelBuilder); 由于继承了 IdentityDbContext 类并调用了父类方法, 现在迁移的话就可以创建 Identity 中默认的一些数据表, 比如 AspNetUsers, AspNetRoles 等... 修改了 DataContext, 故添加一个迁移:dotnet ef migrations add \"AddedIdentity\" -p src/Reactivities.Infrastructure -s src/Reactivities.Web 运行工程, 即可生成对应的数据库表了. 注入 Identity 服务 使用前需要注入 Identity 服务, 在 Startup 类中注入: // 注入 Identity 服务 var builder = services.AddIdentityCore(); var identityBuilder = new IdentityBuilder(builder.UserType, builder.Services); identityBuilder.AddEntityFrameworkStores(); identityBuilder.AddSignInManager>(); 注入服务后启动遇到 SystemClock 服务找不到的问题, 可以手动注入: services.TryAddSingleton(); 详见这个链接. Seed 用户数据 在 Seed 类中进行: public async static Task SeedData(DataContext context, UserManager userManager) { SeedActivity(context); await SeedUsers(userManager); } private async static Task SeedUsers(UserManager userManager) { if (userManager.Users.Any()) return; var users = new List { new AppUser { DisplayName = \"Bob\", UserName = \"bob\", Email = \"bob@test.com\" }, new AppUser { DisplayName = \"Tom\", UserName = \"tom\", Email = \"tom@test.com\" }, new AppUser { DisplayName = \"Jane\", UserName = \"jane\", Email = \"jane@test.com\" }, }; foreach (var user in users) { await userManager.CreateAsync(user, \"Pa$$w0rd\"); } } UserManager 只提供异步 CreateAsync 方法, 故把 SeedData 方法也修改为返回 Task. Main 方法调用 SeedData: var manager = services.GetRequiredService>(); Seed.SeedData(context, manager).Wait() 重启程序后用户即可被添加到数据库中. 创建登录 Handler 使用中介者模式提供登录功能, 实现 Handler. public class Login { public class Query : IRequest { public String Email { get; set; } public String Password { get; set; } } public class QueryValidator : AbstractValidator { public QueryValidator() { RuleFor(x => x.Email).NotEmpty(); RuleFor(x => x.Password).NotEmpty(); } } public class Handler : IRequestHandler { private readonly UserManager _userManager; private readonly SignInManager _signInManager; public Handler(UserManager userManager, SignInManager signInManager) { _userManager = userManager; _signInManager = signInManager; } public async Task Handle(Query request, CancellationToken cancellationToken) { var user = await _userManager.FindByEmailAsync(request.Email); if (user == null) throw new RestException(HttpStatusCode.Unauthorized); var result = await _signInManager.CheckPasswordSignInAsync(user, request.Password, false); if (result.Succeeded) { // TODO: 返回 Token 给用户 return user; } throw new RestException(HttpStatusCode.Unauthorized); } } } 创建登录 API 控制器 登录的 API 控制器如下所示: public class UserController : BaseAPIController { [HttpPost(\"[action]\")] public async Task> Login(Login.Query query) { return await Mediator.Send(query); } } 修改返回的数据类型 之前的实现中是把整个 AppUser 返回给客户端, 这样肯定是不行的, 所以需要将其转换为一个 DTO 再发送, 发送我们希望发送的字段. 创建一个 DTO 类型, 名为 User: /// /// 响应中携带的 DTO /// public class User { public String DisplayName { get; set; } public String Token { get; set; } public String Image { get; set; } public String Username { get; set; } } 将 Login 包装类中的 Handler 和 Query 的泛型参数修改为 User: public class Query : IRequest { // ... } // ... public class Handler : IRequestHandler { // ... public async Task Handle(Query request, CancellationToken cancellationToken) { // ... if (result.Succeeded) { return new User { DisplayName = user.DisplayName, Token = \"待续\", Username = user.UserName, Image = null, }; } // ... } } 修改 API 控制器动作方法返回类型: [HttpPost(\"[action]\")] public async Task> Login(Login.Query query) { // ... } 这样就可以在客户端登录的时候收到类似如下 JSON 了: { \"displayName\": \"Bob\", \"token\": \"待续\", \"image\": null, \"username\": \"bob\" } 实现 Jwt Token 实现过程见源码, 主要步骤: 创建 JwtGenerator 在服务中注入 JwtGenerator 服务 在 Login Handler 中调用生成 Token 在请求处理管线中添加认证和授权, 需要添加在 UseRoute 之后. 在其他 API 上使用注解 [Authorize] 保护. 敏感信息保存 敏感信息保存的时候, 在开发时可以使用 dotnet user-secrets 保存, 在发布时应该设置为环境变量或其他方式保存. 在 .csproj 中添加 0B9A8755-AB5F-4805-AAD6-6740D87AC4DC 一段. 然后就可以在命令行进行保存了: dotnet user-secrets set \"TokenKey\" \"some key to sign token\" -p src/Reactivities.Web 保存 TokenKey dotnet user-secrets list -p src/Reactivities.Web 可以看到打印如下内容: TokenKey = some key to sign token 然后在程序中通过 Key 来获取值了: Configuration[\"TokenKey\"], 其中 Configuration 是 IConfiguration 类型的. 其他地方可以注入 IConfiguration 进行使用. "},"c6/3.html":{"url":"c6/3.html","title":"3 JWT 实现","keywords":"","body":"JWT 实现 JWT 是 JSON Web Token 的简称. 由三部分构成: Header: 说明算法类型和 Token 类型的 JSON 字符串 Payload: 数据 验证指纹: 返回给客户端的 JWT 就是一个字符串, 以 . 分隔三个部分. 每个部分都进行了编码. 可以通过一个单独的工程来提供 JWT. 由于目前演示工程的结构限制, 故把 JWT 生成工程放到 Application 层以上, 让 Web 工程依赖它. "},"m0/r.html":{"url":"m0/r.html","title":"第 M0 章 Docker","keywords":"","body":"Docker 记录使用 Docker 在本地开发和远程部署的相关内容. "},"m0/1.html":{"url":"m0/1.html","title":"1 概述","keywords":"","body":"概述 基本命令 创建一个 Nginx 容器 首先把 Nginx 的 Image 拉下来, 不过通过 run 命令, docker 可以自动拉取. docker container run -p 80:80 nginx 这样就可以在前台运行了. 生成的容器会有一个随机的名字, 如果想手动指定名字, 可以加 --name 参数 每次当我们执行 docker run 的时候, docker 都会生成某个镜像对应的 container, 所以在 ps -a 的时候才会显示多个 container, 即便那个 container 已经停止了. 使用 logs 命令可以查看某个容器的日志. 使用 top 命令可以查看容器进程: docker top containerName Docker Run 命令的背后都发生了什么 首先搜索本地是否存在这个镜像的缓存, 若没有 再在 Docker Hub 中找这个镜像 将镜像下载到本地 基于这个镜像创建新的容器并准备执行 为镜像分配一个位于 Docker 引擎的私有网络上的虚拟 IP 将 Host 上的某个端口转发给容器的某个端口(如果通过 -p 进行过设置) 使用镜像对应的 Dockerfile 中的 CMD 行指定的方式启动容器. 容器和 VM 的对比: 容器仅仅是一个进程 Docker 容器仅仅是一个运行的进程, 这点很容易在 Linux 中验证. 先讲结论: Docker 容器中的应用进行和 Host 中的进程是对应的. 启动一个容器, 这里是 nginx 容器. 执行 docker top nginx容器名, 记录它的信息 执行 ps aux | grep nginx容器名, 对比上一步的信息 可以发现二者是一样的. 一些基础的容器管理命令 使用 -e 参数可以向容器设置环境变量 在运行的 Container 中都发生了什么 top 命令 inspect 命令 stats 命令 三个命令都可以检查正在发生的情况. 和 Container 进行交互 使用 -it 命令连接容器的 shell. exec -it 来运行额外的命令. 在容器运行后, 通过 exec 来运行命令, 比如想要管理 nginx 容器, 可以在它启动的情况下执行: docker container exec -it 容器名 bash 此外介绍一个超小型的 Linux 发行版: Alpine, 在 docker 中可以拉下来, 然后使用 sh 进入, 因为它没有携带 bash. 进入后可以安装 bash. "},"m0/2.html":{"url":"m0/2.html","title":"2 Docker Networking 基础","keywords":"","body":"Docker Networking 基础 本文主要介绍 Docker 的网络基础, 包括: docker container run -p 命令 docker container port 命令查看容器的端口 Docker Networking 的概念 网络包如何在 Docker 内部流转 Docker 的默认 Networking 当启动容器时, 实际是将容器自动连接到了 Docker 的一个特殊网络中. 默认情况下, 这个网络是一个 Bridge 网络. 而这样的网络可以在 Docker 中存在很多个, 这些网络被路由通过 Host 上的 NAT 防火墙. 如果是在 Docker 内部网络中通信的话, 容器就可以不将自己的端口暴露出去, 只要是在同一个网络下, 容器间可以直接通信. 比如一个网络 my_app 中存在 mysql 和 php 容器, 它们可以相互通信, 另外一个网络 my_api 中存在 mongo 和 nodejs 容器, 这两个容器也可以在 my_api 网络下正常通信. 但如果是两个不同网络下的容器, 则无法直接通信. Docker 中的网络可以灵活进行配置: 默认网络可以被很方便地替换或配置 可以创建多个虚拟网络, 就像上面的 my_app 和 my_api 网络那样, 每个网络可以配置自己的安全规则等 可以让一个容器连接到多个虚拟网络, 这样就解决了跨虚拟网络通信的问题. 也可以让容器不连接任何网络. 可以让容器直接连接到 Host 而不使用虚拟网络, 使用 Host 的 IP: --net=host. 可以使用不同的 Docker 网络驱动来获取更多的网络能力. 网络驱动是可插拔的. 通过 CLI 进行网络配置 启动 nginx 容器: docker container run -p 80:80 --name n1 -d nginx, 然后演练一些 CLI 命令. 查看容器的端口配置: docker container port n1, 输出如下: 80/tcp -> 0.0.0.0:80 格式是 hostIP/协议名称 -> container监听 IP:端口 查看容器的 IP 地址: docker container inspect --format 样式字符串 容器名 样式字符串可以是双重大括号括起来的比如 .NetworkSettings.IPAddress 的字符串. 输出如下: 172.17.0.3 这个 IP 即容器在默认虚拟网络下的 IP 地址. 列出所有的虚拟网络: docker network ls: NETWORK ID NAME DRIVER SCOPE 6dd4c3f4dabd bridge bridge local 9565b813a90a host host local a1606d06a4af none null local 其中 bridge 为默认网络, 它桥接过 NAT 防火墙然后到达连接的外部物理网络. 连接到 host 的容器会直接跳过 Docker 的虚拟网络, 直接连接到 Host 的网络接口上. none 网络就是提供给那些不连接到任何网络的容器使用的. 查看网络信息: docker network inspect 包含许多信息, 其中的 Containers 字段中包含的就是所有连接到这个网络的容器信息. 创建 docker 网络: docker network create --driver 比如创建 my_app_net: docker network create my_app_net, 如果不指定 --driver 参数, 则默认使用 bridge. 将容器连接到某网络: docker network connect 比如将某个容器连接到创建的 my_app_net 网络, 就可以使用: docker network connect 网络名 容器名 将容器从某网络端口: docker network disconnect 可以使用: docker network disconnect 网络名 容器名 附 一张手绘网络图形 整体的网络情况就和图中类似. "},"m0/3.html":{"url":"m0/3.html","title":"3 Docker Network DNS","keywords":"","body":"Docker Network DNS 本节介绍 Container 是如何发现各自存在的. 即: 理解 Docker 内部虚拟网络中容器如何利用 DNS 简化相互通信 DNS 在自定义网络中如何工作 使用 --link 在默认的 bridge 网络中启用 DNS 因为 Docker 中的容器和网络都是动态的, 所以不能依靠某个容器的 IP 地址来进行可靠通信, 必须有一种机制在即使容器 IP 发生变化后, 仍然能让通信可靠地进行下去. Docker daemon 拥有一个内建的 DNS 服务器, 所有的容器默认都使用这个服务器. 默认情况下, Docker 使用容器名称作为容器的 hostname, 不过可以自定义 alias. 演示 新建两个容器, 分别名为 n1, n2, 容器连接到同一个网络 my_app_net, 确保两个容器都在运行. 运行如下命令: docker container exec -it n1 ping n2 输出如下所示: 64 bytes from n2.my_app_net (172.18.0.3): icmp_seq=1 ttl=64 time=0.077 ms 64 bytes from n2.my_app_net (172.18.0.3): icmp_seq=2 ttl=64 time=0.099 ms 64 bytes from n2.my_app_net (172.18.0.3): icmp_seq=3 ttl=64 time=0.100 ms 64 bytes from n2.my_app_net (172.18.0.3): icmp_seq=4 ttl=64 time=0.096 ms 64 bytes from n2.my_app_net (172.18.0.3): icmp_seq=5 ttl=64 time=0.105 ms 但默认的网络 bridge 中不能进行 ping 名字, 原因就是它没有使用默认的 DNS 服务器, 比如将 n1 和 n2 连接到默认网络再 ping: docker container exec -it n1 ping n2 则输出为: ping: n2: Name or service not known 不过可以使用 --link 命令将其中的容器连接起来, 但最好的办法还是创建新的虚拟网络. DNS Round Robin 这个概念就是同一个 DNS 记录的名字可以解析到多个 IP, 这样保证多个服务器可用. 在 Docker 中, 可以让位于某个虚拟网络下的多个容器都响应同一个名字. 方法就是使用 -network-alias, 这样就可以给容器一个额外的 DNS 名字, 让它响应某个名字. 这样可以让比如生产和测试环境 APP 响应同一个 DNS 名字. 另外就是多个服务容器部署在同一个虚拟网络下, 可以使用同一个 DNS 名字, 起类似负载均衡的效果, 但又不是真正的负载均衡, 因为服务的选择并不是根据负载决定的... 创建一个新的网络 dude: ➜ ~ docker network create dude 2d12f6430cd4e4a0c86ce8c4b5971c1f1d5e36a469783dc11024301f3b01455f ➜ ~ docker network ls NETWORK ID NAME DRIVER SCOPE 6dd4c3f4dabd bridge bridge local 2d12f6430cd4 dude bridge local 9565b813a90a host host local d2a30bfc26bf my_app_net bridge local a1606d06a4af none null local 启动两个 elasticsearch:2 的容器, 名称让 Docker 随机分配, 重复两次执行如下命令生成两个容器: docker container run -d --net dude --net-alias search elasticsearch:2 上述命令将容器连接到 dude 网络中, 并指定它的网络别名为 search. 验证可以通过 search 这个 DNS 名字访问到这两个容器: docker container run --rm --net dude alpine nslookup search 输出如下所示: Name: search Address: 172.19.0.2 Name: search Address: 172.19.0.3 验证每次请求会分配到不同的容器: docker container run --rm --net dude centos curl -s search:9200 "},"m0/4.html":{"url":"m0/4.html","title":"4 Docker Image","keywords":"","body":"Docker Image 本节来看什么是 Docker Image, 它内部是什么, 怎么找 Image, 怎么构建 Image. 内容如下: 什么是 Image 使用 Docker Hub registry 管理本地的 Image 缓存 构造自己的 Image 什么是 Image Image 具有如下内容和特性: App 的二进制文件以及 APP 的所有依赖 Image 的元数据信息, 以及如何运行这个 Image 的相关指令 官方定义: Image 是一个 root 文件系统的改动序列, 以及在容器运行时里面的相关执行参数的有序集合. Image 并不是一个完整的 OS, 它不包含内核(kernel), 不包含内核模块(比如驱动), 内核是由 Host 提供的. Image 不会启动一个完整的操作系统, 启动它仅仅是启动一个应用程序 Image 可以非常小, 比如 golang 的静态库或你的 APP 的二进制包. Image 也可以非常大, 比如 Ubuntu Image 就可以包含有 apt, apache, PHP 等等. 通过 Docker Hub, 可以找到许多三方或官方的 Image. Image 的 Layer Image 是基于 Union file system 的概念来构建的, 通过 docker history 命令就可以打印一个 Image 的 Layer 历史. 任何 Image 都是从一个空的 Layer 开始构建的, 这个 Layer 称为 scratch, 而之后的每一次对 Image 内部文件系统的改动, 就是一个新的 Layer. 比如自己创建一个 Image, 就像下面图中那样: 如果开发环境和生产环境只是最后的指令不同, 则 Image 的情况如下图所示: 基于同一个 Image 再往上添加内容, 如下所示: 从 Image 到 Container , 则实际上就是在 Image 上面添加了一层可读写 Layer: Image 的识别 有三部分组成唯一识别一个 Image: /:. 官方的 Image 只会是 nginx:Tag 这样的形式, 不需要 user 识别. 而这样的组合和唯一的一个 ImageID 对应, 所以实际上只要 ImageID 相同, Image 就是同一个. 通过 push 命令可以将改动的 Image 推送到自己的仓库中. 需要使用 docker login 先登录, 登录授权 key 会存放在对应的 .docker 目录下的config中. Image 的构建: Dockerfile 这里有一个示例 Dockerfile. 通过 docker build -f 文件名 即可对这个镜像进行构建. 使用带丰富功能的基础镜像好处是可以简化后续流程, 不过也可以从零开始构建小镜像. 每个指令就是在镜像中添加一个 Layer, 所以指令的顺序非常重要. # 基础镜像 # 任何 Dockerfile 都需要有一个 FROM # 如果想从一个空镜像开始构建, 则可以使用 `FROM scratch` FROM debian:jessie # 环境变量, 可选 # 环境变量可以在后续指令中使用, 环境变量在 container 运行时会被设置为 envvar. ENV NGINX_VERSION=1.11.10-1~jessie # 下面这段是简化了的一个 RUN, 实际 nginx 构建的时候比这个复杂, 仅为说明 RUN 指令. # RUN 即在构建时在 container 的 shell 中执行的命令 # 通过 && 连接命令的话可以不用把多个指令分配到多个 Layer, 这样可以节约空间和时间. RUN apt-get update \\ && apt-get install nginx \\ && rm -rf /var/lib/apt/lists/* # 将所有的日志转发到标准输出和标准错误中, 在 Docker 中只能用这样的方式来输出日志. # 其中 stdout 和 stderr 就是 Docker 中的 \"log collector\". # 转发后 Docker 就可以获取这些日志信息了 RUN ln -sf /dev/stdout /var/log/nginx/access.log \\ && ln -sf /dev/stderr /var/log/nginx/error.log # 暴露端口 # 默认情况下, Docker container 中没有任何暴露的端口, 无论 tcp 还是 udp 协议. # 可以通过 EXPOSE 指令将端口暴露到虚拟网络下. # 暴露端口后, 就可以通过 -p/-P 参数在启动时将端口开放/转发到 host 了. EXPOSE 80 443 # CMD一般都是最后一个指令, 且是必须的指令 # 它提供当 container 启动后所要执行的命令, 且只能有一个 CMD 指令存在 # 如果有多个 CMD, 则最后一个将会被执行. CMD [ \"nginx\", \"-g\", \"daemon off;\" ] 通过 Docker build 构建 Image 有了 Dockerfile 来指导 Image 的构建, 下一步就是构建 Image 了. 在构建这个 Image 的时候, docker 会首先拉取基础镜像到本地缓存, 然后根据 Dockerfile 中的内容一行一行地执行, 并将这些 layer 缓存在本地: docker image build -t 标签名 dockerfile文件 比如: docker image build -t customnginx . "},"m0/5.html":{"url":"m0/5.html","title":"5 Docker 容器生命期和数据持久化","keywords":"","body":"Docker 容器生命期和数据持久化 本章的主题有: 容器的核心概念: 不可变, 易失性 使用数据卷(Data Volume) 使用绑定挂载(Bind Mount) 容器是不可变的设施, 故要持久化数据, 需要使用其他的机制来持久化数据. 数据卷 在 Dockerfile 中可以使用 VOLUMN /var/www/html 这样的指令来指定外部生成一个对应的数据卷, 并对应容器中的 /var/www/html 文件夹. 通过 inspect 命令查看容器时, 就可以发现有一个 Mounts 字段, 这个字段如下所示: \"Mounts\": [ { \"Type\": \"bind\", \"Source\": \"/Users/ray/workspace/BackEnd/mysql/logs\", \"Destination\": \"/logs\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" }, { \"Type\": \"bind\", \"Source\": \"/Users/ray/workspace/BackEnd/mysql/data\", \"Destination\": \"/mysql_data\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" }, { \"Type\": \"volume\", \"Name\": \"8502dfc60519be1f2615853d071d97f19adc292d66ac7be6504d0a35d80cf69b\", \"Source\": \"/var/lib/docker/volumes/8502dfc60519be1f2615853d071d97f19adc292d66ac7be6504d0a35d80cf69b/_data\", \"Destination\": \"/var/lib/mysql\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" } ] 可以在启动容器的时候使用 -v 数据卷名称:容器文件夹路径 的方式来指定数据卷的名字. 一个好的实践是把数据卷的名字命名为工程名称或工程名称-数据类别的形式. 绑定挂载 使用绑定挂载也是相同的操作, 使用 -v host文件夹或文件:容器文件夹或文件. 这个最大的用途是它可以和本地文件夹同步, 这样的话使用 docker 开发会非常简单. "},"m0/6.html":{"url":"m0/6.html","title":"6 Docker Compose的使用","keywords":"","body":"Docker Compose的使用 本节主要介绍: 通过 Docker Compose 配置容器之间的关系 使用简单易读的文本来保存容器的配置 配置单行的开发环境启动 将如下两个内容关联起来: 使用 YAML 文件描述解决方案配置, 包括 容器(Container) 网络(network) 数据卷(volume) 使用 docker-compose 命令行工具将本地开发/测试工作自动化 docker-compose.yml 文件用于: 记录使用的 compose 的版本信息 被命令行工具用来进行本地自动化 被 docker 用来直接处理生产环境下的 Swarm 配置 默认的 compose 文件名是 docker-compose.yml, 但可以通过 docker-compose -f 命令指定文件名. docker compose 配置文件简介 一个典型的 docker-compose 文件如下所示: # 通过 shell 脚本也可以达到相同的效果, 不过通过这个 yaml 文件更加可读且易于维护. version: '3.1' services: # 表示 containers, 和 docker container run 一样 servicename: # 一个易读的container名称, 它也用于 network 中的 DNS 名字 # 可选, 如果要使用 docker build 的话就要有这个 image: mysql command: # 可选, 通过这个指令来替代 image 用原有的 CMD 指令 environment: # 可选, 用来设置环境变量, 作用和 docker container run 中 -e 参数相同 KEY0: VALUE0 volumes: # 可选, 作用和 docker container run 中 -v 参数相同 - ./data:/var/lib/mysql ports: - \"80:4000\" # 可选, 作用和 docker container run 中的 -p 参数相同, 将host端口和container端口进行绑定. depends_on: # 可选, 用来描述服务(Container)之间的关系 - servicename2 servicename2: # 第二个 container 的名称, 保证名字唯一即可 volumes: # 可选, 作用和 docker volume create 相同 networks: # 可选, 作用和 docker network create 相同 更多的内容可以参考 docker 文档. docker-compose 命令行工具的使用 在 mac 和 windows 上面这个工具自带, 在 linux 上需要额外安装. 它不是一个生产级别的工具, 但在本地开发测试中非常常用. 两个典型的命令: docker-compose up: 根据配置文件进行容器/网络/数据卷的配置并启动所有的容器. docker-compose down: 停止所有的容器并移除容器/网络/数据卷? 如果在开发的所有项目都有一个 Dockerfile, 然后通过 docker-comse.yml 文件组合它们, 则启动所有工程的步骤就简化为如下: 克隆项目到机器上: git clone ... docker-compose up(如果想后台运行, 只需要加 -d 参数即可) 在 linux 机器上需要在 docker compose 的 github 主页上找到需要的版本, 根据安装命令进行安装即可. 如果需要重新构建镜像, 可以使用 docker-compose build 命令. "},"m1/r.html":{"url":"m1/r.html","title":"第 M1 章 在开发过程中使用 Docker","keywords":"","body":"第 M1 章 在开发过程中使用 Docker 本章主要介绍如何在开发过程中使用 docker. "},"m1/1.html":{"url":"m1/1.html","title":"1 概述","keywords":"","body":"概述 本文主要参考如下文档: 官方文档: Docker APP 的开发工作流 VS Code 文档 官方文档: sln 下的 docker 开发处理 官方文档: Docker APP 的开发工作流概述 在本地开发过程中使用 docker, 意味着无论选择何种框架, 何种语言, 何种平台, 实际上都是在本地进行 docker 容器的开发. 每个容器(docker image 的实例)都包含如下组成部分: 选择的操作系统 在开发过程中添加的文件 配置信息, 比如环境配置和依赖配置. 基于 docker 的 APP 开发工作流 本节仅关注在开发者机器上进行 APP 开发时候的工作流程. 整体流程如下所示: 下面就来分步骤讲解整个过程. Step1 编写代码 开发基于 docker 的应用和开发普通应用的方式类似. 在本地安装好开发环境, 然后进行开发. 推荐尽早在开发中引入 Docker, 因为这样可以保证环境的统一. Step2 基于现有的 .NET 镜像编写一个 Dockerfile 针对每个自定义镜像(服务容器)都需要有一个对应的 Dockerfile, 如果 APP 由一个服务组成, 则只需要一个 Dockerfile, 否则每个服务都对应一个 Dockerfile. Dockerfile 放在 APP 的根目录或每个服务的根目录. 其中包含在容器中运行APP或服务的指令. 然后基于官方镜像进行分段处理, 即基于 sdk 镜像编译后, 再基于 runtime 镜像执行. In short, multi-stage builds allow splitting the creation in different \"phases\" and then assemble the final image taking only the relevant directories from the intermediate stages. 实践 由于 Docker 运行的进程就是本机进程, 故可以直接进行 debug, VS Code 也提供了便捷的功能, 不用手动去 attach. 步骤: 示例工程(单一 proj 工程)的docker build和debug: 和 VS Code 文档的流程一致. 多service工程(带sln工程)的docker build和debug. 带 watch 的工作流. 1 单一工程 Dockerfile 如下所示: FROM mcr.azk8s.cn/dotnet/core/aspnet:3.1 AS base WORKDIR /app EXPOSE 5000 ENV ASPNETCORE_URLS=http://*:5000 FROM mcr.azk8s.cn/dotnet/core/sdk:3.1 AS build WORKDIR /src COPY [\"DemoAPI.csproj\", \"./\"] RUN dotnet restore \"./DemoAPI.csproj\" COPY . . WORKDIR /src/. RUN dotnet build \"DemoAPI.csproj\" -c Release -o /app/build FROM build AS publish RUN dotnet publish \"DemoAPI.csproj\" -c Release -o /app/publish FROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [\"dotnet\", \"DemoAPI.dll\"] 选择 docker build, 实际上是执行一个 docker build 命令: docker build --rm --pull -f \"/Users/ray/workspace/BackEnd/DemoAPI/Dockerfile\" --label \"com.microsoft.created-by=visual-studio-code\" -t \"demoapi:latest\" \"/Users/ray/workspace/BackEnd/DemoAPI\" 然后再使用 debug 中的 docker debug 即可. 多工程的 sln 只是 Docker file 编写不一样: # 国内使用 mcr.azk8s.cn 镜像地址... FROM mcr.azk8s.cn/dotnet/core/sdk:3.1 AS build WORKDIR /app # 拷贝所有文件到工作目录 COPY . . # restore 后 publish RUN dotnet restore && dotnet publish -c Release -o /app/out FROM mcr.azk8s.cn/dotnet/core/aspnet:3.1 AS runtime WORKDIR /app # 将所有发布的文件拷贝到工作目录. COPY --from=build /app/out ./ EXPOSE 5000 ENV ASPNETCORE_URLS=http://*:5000 # 启动 ENTRYPOINT [\"dotnet\", \"DemoMultiPrj.Api.dll\"] 带 watch 方式 "},"m2/r.html":{"url":"m2/r.html","title":"M2 后端开发路线图","keywords":"","body":"后端开发路线图 参考 github 上面的后端开发路线图写成. 总体路线如下, 按循序渐进的顺序: 对计算机网络和 Internet 的基本了解. 基础的前端开发知识 计算机操作系统和一些通用知识的掌握 开发语言 版本控制系统(Git 等) 关系型数据库 数据库深入: 非关系型数据库(NoSQL), 数据存储的相关知识. API 的相关知识 缓存 Web 安全相关知识 软件测试 持续集成/部署 软件设计和开发的原则: SOLID 等 架构模式: CQRS, 微服务, 单体 APP 等 消息代理(Message Broker) 虚拟化和容器化 GraphQL 图数据库 WebSocket Web Server: 比如 Nginx 等 实现易于扩展的架构 "},"m2/1.html":{"url":"m2/1.html","title":"1 计算机网络","keywords":"","body":"计算机网络 主要了解如下内容 internet 的工作原理 什么是 HTTP? 浏览器的运行原理 DNS 及其原理 什么是 Domain Name(域名)? 什么是 hosting? 待续... "}}